Large Language Models This module covers the practical usage of large language models (LLMs). LLMs incur a cost. For the May 2025 batch, use aipipe.org as a proxy.
Emails with @ds.study.iitm.ac.in get a $1 per calendar month allowance. (Don't exceed that.) Read the AI Pipe documentation to learn how to use it. But in short: Replace OPENAI_BASE_URL , i.e. https://api.openai.com/v1 with https://aipipe.org/openrouter/v1... or https://aipipe.org/openai/v1... Replace OPENAI_API_KEY with the AIPIPE_TOKEN Replace model names, e.g. gpt-4.1-nano , with openai/gpt-4.1-nano For example, let's use Gemini 2.0 Flash Lite via OpenRouter for chat completions and Text Embedding 3 Small via OpenAI for embeddings: ```bash
curl https://aipipe.org/openrouter/v1/chat/completions \
 -H "Content-Type: application/json" \
 -H "Authorization: Bearer $AIPIPE_TOKEN" \
 -d '{
 "model": "google/gemini-2.0-flash-lite-001",
 "messages": [{ "role": "user", "content": "What is 2 + 2?"} }]
 }' curl https://aipipe.org/op

---

