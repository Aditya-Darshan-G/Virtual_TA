ect(".ipc-rating-star")
 else None
 )

 if title and year and rating:
 movies.append({"title": title, "year": year, "rating": rating})

return movies Scrape data and save with timestamp now = datetime.now(UTC)
with open(f'imdb-top250-{now.strftime("%Y-%m-%d")}.json', "a") as f:
 f.write(json.dumps({"timestamp": now.isoformat(), "movies": scrape_imdb()}) + "\n")
``` Here's a sample .github/workflows/imdb-top250.yml that runs the scraper daily and saves the data: ```yaml
name: Scrape IMDb Top 250 on:
 schedule:
 # Runs at 00:00 UTC every day
 - cron: "0 0 * * *"
 workflow_dispatch: # Allow manual triggers jobs:
 scrape-imdb:
 runs-on: ubuntu-latest
 permissions:
 contents: write steps:
 - name: Checkout repository
 uses: actions/checkout@v4

 - name: Install uv
 uses: astral-sh/setup-uv@v5

 - name: Run scraper
 run: | # python
 uv run --with httpx,lxml,cssselect python scrape.py

 - name: Commit and push changes
 run: |
 git config --local user.email "github-actions[bot]@users.noreply.g

---

