},
 "logprobs": null,
 "finish_reason": "stop"
 }
 ],
 "usage": {
 "prompt_tokens": 592,
 "completion_tokens": 33,
 "total_tokens": 625,
 "prompt_tokens_details": {
 "cached_tokens": 0,
 "audio_tokens": 0
 },
 "completion_tokens_details": {
 "reasoning_tokens": 0,
 "audio_tokens": 0,
 "accepted_prediction_tokens": 0,
 "rejected_prediction_tokens": 0
 }
 },
 "service_tier": "default",
 "system_fingerprint": "fp_bd83329f63",
 "monthlyCost": 0.05490624000000001,
 "cost": 0.001974,
 "monthlyRequests": 14,
 "costError": "crypto.createHash is not a function"
} Error: Model must be gpt-4o-mini

Hi Nilay, nilaychugh: both the URLs use same port, You can run two servers on different port numbers.

Hi Vikash, I looked at your answers in backend. In answer you submitted response from openai, but you need to submit json object which is required for sending a request to LLM. Kind regards

You made same mistake here, instead of response use json body thatâ€™s required for sending request to LLM.

---

